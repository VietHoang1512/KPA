adam_epsilon: 1.0e-08
do_inference: true
do_train: false
early_stop: 10
evaluate_during_training: true
experiment: pseudolabel
gradient_accumulation_steps: 1
learning_rate: 3.0e-05
logging_dir: outputs/pseudo_label/
logging_steps: 20
max_grad_norm: 1.0
no_cuda: false
num_train_epochs: 5.0
num_workers: 4
output_dir: outputs/pseudo_label/
overwrite_output_dir: true
seed: 0
train_batch_size: 1
val_batch_size: 128
warmup_steps: 0
weight_decay: 0.0
